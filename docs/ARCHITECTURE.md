# DTC API SDK - Architecture

This document provides architectural overview of the Aparavi Data Toolchain API SDK with visual diagrams.

## SDK Architecture Overview

### High-Level SDK Structure

```mermaid
graph TB
    subgraph "DTC API SDK"
        Client[DTCApiClient]
        Models[Data Models]
        Exceptions[Exception Handling]
        Config[Configuration]
    end
    
    subgraph "Core Components"
        Client --> Auth[Authentication]
        Client --> HTTP[HTTP Client]
        Client --> Retry[Retry Logic]
        Client --> Timeout[Timeout Management]
        
        Models --> Response[APIResponse]
        Models --> Pipeline[PipelineConfig]
        Models --> Task[TaskInfo]
        Models --> Service[ServiceInfo]
        
        Exceptions --> Base[DTCApiError]
        Exceptions --> AuthErr[AuthenticationError]
        Exceptions --> Valid[ValidationError]
        Exceptions --> Net[NetworkError]
    end
    
    subgraph "API Endpoints"
        Health[Health Check]
        Pipes[Pipeline Management]
        Tasks[Task Execution]
        Files[File Operations]
        Webhooks[Webhook Integration]
        Services[Service Management]
    end
    
    Client --> Health
    Client --> Pipes
    Client --> Tasks
    Client --> Files
    Client --> Webhooks
    Client --> Services
```

### Webhook Processing Architecture (Recommended Approach)

The webhook approach is the **recommended method** for programmatic data extraction, providing direct API access to processed results without web interfaces.

```mermaid
graph TD
    subgraph "Application Layer"
        App[ğŸ“± Your Application]
        SDK[ğŸ”§ DTC SDK]
    end
    
    subgraph "Pipeline Creation"
        WebhookPipe[ğŸª Webhook Pipeline<br/>webhook â†’ parse â†’ response]
        TaskToken[ğŸ« Task Token<br/>Generated ID]
    end
    
    subgraph "Data Processing"
        WebhookReceiver[ğŸ“¥ Webhook Receiver<br/>Accepts Base64 files]
        ParseEngine[ğŸ”„ Parse Engine<br/>Extracts text/data]
        ResponseFormatter[ğŸ“¤ Response Formatter<br/>Returns structured data]
    end
    
    subgraph "Retry & Timeout Management"
        RetryLogic[ğŸ”„ Automatic Retry<br/>3 attempts, progressive backoff]
        TimeoutHandler[â±ï¸ Timeout Management<br/>60-90 seconds for processing]
        ConnectionHandling[ğŸ”— Connection Handling<br/>Robust error recovery]
    end
    
    subgraph "Output"
        StructuredData[ğŸ“Š Structured Data<br/>JSON with extracted content]
        ExtractedText[ğŸ“„ Extracted Text<br/>Readable content]
        Metadata[ğŸ“‹ File Metadata<br/>Size, type, encoding]
    end
    
    App --> SDK
    SDK --> WebhookPipe
    WebhookPipe --> TaskToken
    
    SDK --> |"send_webhook(token, data)"| WebhookReceiver
    WebhookReceiver --> ParseEngine
    ParseEngine --> ResponseFormatter
    
    SDK --> RetryLogic
    RetryLogic --> TimeoutHandler
    TimeoutHandler --> ConnectionHandling
    
    ResponseFormatter --> StructuredData
    StructuredData --> ExtractedText
    StructuredData --> Metadata
    
    ExtractedText --> App
    Metadata --> App
```

### Working Webhook Pipeline Configuration

```mermaid
graph LR
    subgraph "Pipeline Structure"
        PipelineWrapper["{'pipeline': {...}}"]
        
        subgraph "Required Components"
            Source[source: 'webhook_1']
            Components[components: [...]]
            ID[id: 'webhook-processor']
        end
        
        PipelineWrapper --> Source
        PipelineWrapper --> Components
        PipelineWrapper --> ID
    end
    
    subgraph "Component Chain"
        Webhook[ğŸª webhook_1<br/>provider: webhook<br/>mode: Source]
        Parse[ğŸ”„ parse_1<br/>provider: parse<br/>input: tags from webhook_1]
        Response[ğŸ“¤ response_1<br/>provider: response<br/>input: text from parse_1]
        
        Webhook --> |"lane: tags"| Parse
        Parse --> |"lane: text"| Response
    end
    
    Source -.->|"references"| Webhook
    Components --> Webhook
    Components --> Parse
    Components --> Response
```

## Complete Webhook Workflow Implementation

### Step-by-Step Processing Flow

```mermaid
sequenceDiagram
    participant App as Application
    participant SDK as DTC SDK
    participant API as DTC API
    participant Engine as Processing Engine
    
    Note over App,Engine: Phase 1: Setup & Authentication
    App->>SDK: Initialize DTCApiClient(api_key)
    SDK->>API: Authenticate
    API-->>SDK: âœ… Authentication Success
    
    Note over App,Engine: Phase 2: Pipeline Creation
    App->>SDK: create_webhook_pipeline()
    SDK->>API: POST /pipe (webhookâ†’parseâ†’response)
    API-->>SDK: Task Token
    
    Note over App,Engine: Phase 3: Data Submission with Retry Logic
    App->>SDK: send_webhook(token, file_data)
    
    loop Retry Logic (max 3 attempts)
        SDK->>API: PUT /webhook?token=xxx
        alt Success
            API->>Engine: Start Processing
            Engine-->>API: Processing Complete
            API-->>SDK: âœ… Structured Results
        else Connection/Timeout Error
            SDK->>SDK: Wait (progressive backoff)
            Note over SDK: Retry attempt with longer timeout
        end
    end
    
    Note over App,Engine: Phase 4: Result Processing
    SDK->>SDK: Parse response structure
    SDK-->>App: ğŸ“Š Extracted Data (JSON)
    
    Note over App,Engine: Available Data Types
    Note over App: â€¢ Extracted text content<br/>â€¢ File metadata<br/>â€¢ Processing statistics<br/>â€¢ Structured objects
```

### Robust Error Handling & Timeout Management

```mermaid
graph TD
    subgraph "Connection Management"
        InitialRequest[ğŸ“¤ Initial Webhook Request<br/>Timeout: 60s default]
        
        subgraph "Error Detection"
            ConnError[ğŸ”Œ Connection Failed]
            TimeoutError[â° Request Timeout]
            ServerError[ğŸš« Server Error 5xx]
            AuthError[ğŸ” Auth Error 401]
        end
        
        subgraph "Recovery Strategy"
            RetryDecision{Retry Possible?}
            BackoffWait[â³ Progressive Backoff<br/>5s â†’ 8s â†’ 11s]
            TimeoutIncrease[ğŸ“ˆ Increase Timeout<br/>60s â†’ 90s â†’ 120s]
            FallbackMethod[ğŸ”„ Try Direct HTTP]
        end
        
        subgraph "Final Outcomes"
            Success[âœ… Data Retrieved]
            FinalFailure[âŒ All Attempts Failed]
            UserAction[ğŸ‘¤ User Intervention Needed]
        end
    end
    
    InitialRequest --> ConnError
    InitialRequest --> TimeoutError
    InitialRequest --> ServerError
    InitialRequest --> AuthError
    InitialRequest --> Success
    
    ConnError --> RetryDecision
    TimeoutError --> RetryDecision
    ServerError --> RetryDecision
    
    RetryDecision -->|Yes, attempt < 3| BackoffWait
    RetryDecision -->|No| FinalFailure
    
    BackoffWait --> TimeoutIncrease
    TimeoutIncrease --> FallbackMethod
    FallbackMethod --> InitialRequest
    
    AuthError --> UserAction
    FinalFailure --> UserAction
```

## API Communication Flow

### Enhanced Authentication & Processing Flow

```mermaid
sequenceDiagram
    participant App as Application
    participant SDK as DTC SDK
    participant API as DTC API
    participant Engine as Processing Engine
    
    App->>SDK: Initialize Client
    SDK->>API: Authenticate (Bearer Token)
    API-->>SDK: Authentication Success
    
    App->>SDK: Create Webhook Pipeline
    SDK->>SDK: Build pipeline config
    Note over SDK: {webhook_1 â†’ parse_1 â†’ response_1}
    SDK->>API: POST /pipe (Create Pipeline)
    API-->>SDK: Pipeline Token
    
    App->>SDK: Process File (Base64 data)
    SDK->>SDK: Prepare webhook payload
    Note over SDK: {filename, content_type, size, data}
    
    loop Retry with Timeout Management
        SDK->>API: PUT /webhook (with extended timeout)
        API->>Engine: Start Processing
        Engine->>Engine: Parse Document
        Engine->>Engine: Extract Text & Metadata
        Engine-->>API: Processing Complete
        API-->>SDK: Structured Results
    end
    
    SDK->>SDK: Parse Response
    Note over SDK: Extract objects, text, metadata
    SDK-->>App: Processed Data (JSON)
    
    App->>App: Use Extracted Content
    Note over App: â€¢ Text content for analysis<br/>â€¢ Metadata for cataloging<br/>â€¢ Structured data for processing
```

## Pipeline Architecture

### Webhook-First Processing Pipeline

```mermaid
graph TD
    subgraph "Input Processing"
        File[ğŸ“„ Input File<br/>PDF, DOC, TXT, Images]
        Base64[ğŸ”¢ Base64 Encoding<br/>File â†’ Base64 string]
        Payload[ğŸ“¦ Webhook Payload<br/>JSON with file data]
    end
    
    subgraph "Pipeline Components"
        Webhook[ğŸª Webhook Component<br/>â€¢ id: webhook_1<br/>â€¢ provider: webhook<br/>â€¢ mode: Source<br/>â€¢ hideForm: true]
        
        Parse[ğŸ”„ Parse Component<br/>â€¢ id: parse_1<br/>â€¢ provider: parse<br/>â€¢ input: tags from webhook_1<br/>â€¢ Extracts text & structure]
        
        Response[ğŸ“¤ Response Component<br/>â€¢ id: response_1<br/>â€¢ provider: response<br/>â€¢ input: text from parse_1<br/>â€¢ Returns structured data]
    end
    
    subgraph "Data Flow"
        TagsLane[ğŸ“‹ Tags Lane<br/>File metadata & properties]
        TextLane[ğŸ“ Text Lane<br/>Extracted content]
        OutputLane[ğŸ“Š Output Lane<br/>Final structured result]
    end
    
    subgraph "Output Structure"
        Objects[ğŸ—‚ï¸ Objects Dictionary<br/>Processed file data]
        ExtractedText[ğŸ“„ Extracted Text<br/>Readable content]
        Metadata[ğŸ“Š File Metadata<br/>Type, size, encoding]
        Stats[ğŸ“ˆ Processing Stats<br/>Objects requested/completed]
    end
    
    File --> Base64
    Base64 --> Payload
    Payload --> Webhook
    
    Webhook --> TagsLane
    TagsLane --> Parse
    
    Parse --> TextLane
    TextLane --> Response
    
    Response --> OutputLane
    OutputLane --> Objects
    Objects --> ExtractedText
    Objects --> Metadata
    Objects --> Stats
```

### Response Data Structure

```mermaid
graph LR
    subgraph "Webhook Response Format"
        Root[ğŸ“Š Response Object]
        
        subgraph "Top Level"
            Objects[objects: {...}]
            Types[types: {...}]
            Requested[objectsRequested: int]
            Completed[objectsCompleted: int]
        end
        
        subgraph "Objects Content"
            ObjectID[UUID: object-id]
            ObjTypes[__types: {text: 'text'}]
            ObjMeta[metadata: {...}]
            ObjName[name: string]
            ObjPath[path: string]
            ObjText[text: [extracted_content]]
        end
        
        Root --> Objects
        Root --> Types
        Root --> Requested
        Root --> Completed
        
        Objects --> ObjectID
        ObjectID --> ObjTypes
        ObjectID --> ObjMeta
        ObjectID --> ObjName
        ObjectID --> ObjPath
        ObjectID --> ObjText
    end
```

## Production Implementation Best Practices

### Timeout & Performance Configuration

```mermaid
graph TB
    subgraph "Timeout Strategy"
        BaseTimeout[â±ï¸ Base Timeout: 60s<br/>Standard processing]
        ExtendedTimeout[â±ï¸ Extended: 90s<br/>Large files/complex processing]
        MaxTimeout[â±ï¸ Maximum: 120s<br/>Final retry attempt]
        
        subgraph "File Size Considerations"
            SmallFiles[ğŸ“„ < 1MB: 60s timeout]
            MediumFiles[ğŸ“„ 1-10MB: 90s timeout]
            LargeFiles[ğŸ“„ > 10MB: 120s timeout]
        end
        
        BaseTimeout --> SmallFiles
        ExtendedTimeout --> MediumFiles
        MaxTimeout --> LargeFiles
    end
    
    subgraph "Retry Configuration"
        Attempt1[ğŸ”„ Attempt 1<br/>Standard timeout]
        Attempt2[ğŸ”„ Attempt 2<br/>Extended timeout + 5s wait]
        Attempt3[ğŸ”„ Attempt 3<br/>Maximum timeout + 8s wait]
        FinalFallback[ğŸš« Fallback<br/>Direct HTTP attempt]
        
        Attempt1 --> |Fail| Attempt2
        Attempt2 --> |Fail| Attempt3
        Attempt3 --> |Fail| FinalFallback
    end
```

### Production-Ready Implementation Template

```python
def create_production_webhook_pipeline():
    """Production-ready webhook pipeline with all required components."""
    return {
        "pipeline": {
            "source": "webhook_1",
            "components": [
                {
                    "id": "webhook_1",
                    "provider": "webhook",
                    "config": {
                        "hideForm": True,
                        "mode": "Source",
                        "type": "webhook"
                    }
                },
                {
                    "id": "parse_1",
                    "provider": "parse",
                    "config": {},
                    "input": [
                        {
                            "lane": "tags",
                            "from": "webhook_1"
                        }
                    ]
                },
                {
                    "id": "response_1",
                    "provider": "response",
                    "config": {
                        "lanes": []
                    },
                    "input": [
                        {
                            "lane": "text",
                            "from": "parse_1"
                        }
                    ]
                }
            ],
            "id": "production-webhook-processor"
        }
    }

def robust_webhook_processing(client, task_token, file_data, max_retries=3):
    """Production webhook processing with comprehensive error handling."""
    for attempt in range(max_retries):
        try:
            # Progressive timeout increase
            timeout = 60 + (attempt * 30)  # 60s, 90s, 120s
            client.timeout = timeout
            
            response = client.send_webhook(task_token, file_data)
            
            # Parse and return structured data
            return extract_structured_data(response)
            
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 5 + (attempt * 3)  # Progressive backoff
                time.sleep(wait_time)
            else:
                raise Exception(f"All webhook attempts failed: {e}")
```

## SDK Component Relationships

### Enhanced Class Hierarchy

```mermaid
classDiagram
    class DTCApiClient {
        +api_key: str
        +base_url: str
        +timeout: int
        +max_retries: int
        +session: Session
        +get_version()
        +get_status()
        +create_pipeline()
        +execute_task()
        +upload_files()
        +send_webhook()
        +robust_webhook_call()
    }
    
    class WebhookPipeline {
        +source: str
        +components: List[Component]
        +pipeline_id: str
        +create_webhook_config()
        +validate_pipeline()
    }
    
    class APIResponse {
        +status: ResponseStatus
        +data: Dict
        +error: Dict
        +metrics: Dict
        +objects: Dict
        +extracted_text: str
        +metadata: Dict
        +is_success: bool
        +error_message: str
    }
    
    class TaskInfo {
        +token: str
        +status: TaskStatus
        +name: str
        +progress: float
        +result: Dict
        +processing_time: float
    }
    
    class RetryManager {
        +max_attempts: int
        +base_timeout: int
        +backoff_strategy: str
        +execute_with_retry()
        +calculate_timeout()
        +handle_failure()
    }
    
    class DTCApiError {
        +message: str
        +status_code: int
        +response_data: dict
        +retry_recommended: bool
    }
    
    DTCApiError <|-- AuthenticationError
    DTCApiError <|-- ValidationError
    DTCApiError <|-- PipelineError
    DTCApiError <|-- TaskError
    DTCApiError <|-- NetworkError
    DTCApiError <|-- TimeoutError
    
    DTCApiClient --> WebhookPipeline
    DTCApiClient --> APIResponse
    DTCApiClient --> TaskInfo
    DTCApiClient --> RetryManager
    DTCApiClient --> DTCApiError
```

## Key Advantages of Webhook Approach

### Why Webhook Processing is Recommended

```mermaid
graph TB
    subgraph "Traditional Approach Limitations"
        FileUpload[ğŸ“ File Upload Approach]
        WebInterface[ğŸŒ Web Interface Results]
        ManualRetrieval[ğŸ‘¤ Manual Result Retrieval]
        
        FileUpload --> WebInterface
        WebInterface --> ManualRetrieval
    end
    
    subgraph "Webhook Approach Benefits"
        DirectAPI[ğŸ”Œ Direct API Integration]
        ProgrammaticAccess[ğŸ’» Programmatic Access]
        StructuredResults[ğŸ“Š Structured Results]
        AutomatedWorkflow[ğŸ¤– Automated Workflow]
        RobustErrorHandling[ğŸ›¡ï¸ Robust Error Handling]
        
        DirectAPI --> ProgrammaticAccess
        ProgrammaticAccess --> StructuredResults
        StructuredResults --> AutomatedWorkflow
        AutomatedWorkflow --> RobustErrorHandling
    end
    
    subgraph "Production Benefits"
        Scalability[ğŸ“ˆ Scalable Processing]
        Integration[ğŸ”— Easy Integration]
        Monitoring[ğŸ“Š Built-in Monitoring]
        ErrorRecovery[ğŸ”„ Automatic Recovery]
        
        RobustErrorHandling --> Scalability
        RobustErrorHandling --> Integration
        RobustErrorHandling --> Monitoring
        RobustErrorHandling --> ErrorRecovery
    end
```

### Performance Characteristics

- **Timeout Management**: 60-120 seconds based on file size and complexity
- **Retry Logic**: 3 attempts with progressive backoff (5s, 8s, 11s)
- **Connection Handling**: Automatic recovery from network issues
- **Memory Efficiency**: Streaming base64 encoding for large files
- **Error Transparency**: Detailed error reporting for debugging

---

## Summary

The DTC API SDK provides a **production-ready webhook processing architecture** that eliminates the need for web interfaces and provides direct programmatic access to extracted data. Key features include:

- **Complete Webhook Integration**: webhook â†’ parse â†’ response pipeline pattern
- **Robust Error Handling**: Automatic retry with progressive timeouts
- **Structured Data Output**: JSON responses with extracted text, metadata, and statistics
- **Production Ready**: Built-in timeout management, connection recovery, and comprehensive error handling
- **Developer Friendly**: No web interfaces required - pure API-driven workflow

The webhook approach is the **recommended method** for all production integrations, providing reliable, scalable, and fully automated document processing capabilities. 