#!/usr/bin/env python3
"""
Audio Transcription Example for DTC API SDK

This example demonstrates processing an MP4 file to extract and transcribe audio content.
Pipeline flow: File Upload â†’ Parse â†’ Audio Transcribe â†’ Response

Based on the pipeline: dropper â†’ parse â†’ audio_transcribe â†’ response
"""

import os
import time
from pathlib import Path
from dtc_api_sdk import DTCApiClient
from dtc_api_sdk.exceptions import DTCApiError


def create_audio_transcription_pipeline():
    """Create the audio transcription pipeline configuration."""
    return {
        "pipeline": {
            "source": "dropper_1",
            "components": [
                {
                    "id": "dropper_1",
                    "provider": "dropper",
                    "config": {
                        "hideForm": True,
                        "mode": "Source",
                        "type": "dropper"
                    }
                },
                {
                    "id": "parse_1",
                    "provider": "parse",
                    "config": {},
                    "input": [
                        {
                            "lane": "tags",
                            "from": "dropper_1"
                        }
                    ]
                },
                {
                    "id": "audio_transcribe_1",
                    "provider": "audio_transcribe",
                    "config": {
                        "profile": "default",
                        "default": {
                            "max_seconds": 300,
                            "min_seconds": 240,
                            "model": "base",
                            "silence_threshold": 0.25,
                            "vad_level": 1
                        }
                    },
                    "input": [
                        {
                            "lane": "video",
                            "from": "parse_1"
                        },
                        {
                            "lane": "audio",
                            "from": "parse_1"
                        }
                    ]
                },
                {
                    "id": "response_1",
                    "provider": "response",
                    "config": {
                        "lanes": ["text"]
                    },
                    "input": [
                        {
                            "lane": "text",
                            "from": "audio_transcribe_1"
                        }
                    ]
                }
            ],
            "id": "audio-transcription-pipeline"
        }
    }


def process_audio_file(file_path: str):
    """Process an audio/video file for transcription."""
    print("ğŸµ Audio Transcription Pipeline")
    print("=" * 50)
    
    # Initialize client
    client = DTCApiClient()
    
    # Check if file exists
    audio_file = Path(file_path)
    if not audio_file.exists():
        print(f"âŒ File not found: {file_path}")
        return
    
    print(f"ğŸ“ Processing file: {audio_file.name}")
    print(f"ğŸ“Š File size: {audio_file.stat().st_size / (1024*1024):.2f} MB")
    
    # Create pipeline configuration
    pipeline_config = create_audio_transcription_pipeline()
    
    try:
        # Step 1: Validate pipeline configuration
        print("\nğŸ” Step 1: Validating pipeline configuration...")
        is_valid = client.validate_pipeline(pipeline_config)
        print(f"   âœ… Pipeline validation: {'Valid' if is_valid else 'Invalid'}")
        
        if not is_valid:
            print("âŒ Pipeline configuration is invalid. Exiting.")
            return
        
        # Step 2: Create pipeline
        print("\nğŸ”§ Step 2: Creating pipeline...")
        pipeline_token = client.create_pipeline(
            config=pipeline_config,
            name="audio_transcription_demo"
        )
        print(f"   âœ… Pipeline created! Token: {pipeline_token[:8]}...")
        
        # Step 3: Upload file
        print(f"\nğŸ“¤ Step 3: Uploading file...")
        upload_success = client.upload_files(
            token=pipeline_token,
            files=[str(audio_file)]
        )
        print(f"   âœ… File uploaded: {upload_success}")
        
        # Step 4: Get dropper URL for alternative upload method
        print(f"\nğŸŒ Step 4: Getting interface URLs...")
        try:
            dropper_url = client.get_dropper_url(pipeline_token, "audio_transcribe")
            print(f"   âœ… Dropper URL: {dropper_url}")
            print("   ğŸ“ You can also upload files via this web interface!")
        except Exception as e:
            print(f"   âš ï¸  Dropper URL error: {e}")
        
        # Step 5: Monitor processing
        print(f"\nâ³ Step 5: Monitoring processing...")
        print("   ğŸµ Extracting audio from video...")
        print("   ğŸ—£ï¸  Transcribing audio content...")
        print("   ğŸ“ Generating text output...")
        
        # Note: Since this is a pipeline (not a task), we can't directly monitor progress
        # In a real scenario, you might need to implement webhook endpoints or polling
        print("   âš ï¸  Pipeline processing started. Check the dropper interface for results.")
        
        # Step 6: Alternative - Use task execution for direct monitoring
        print(f"\nğŸ”„ Step 6: Alternative - Execute as task for monitoring...")
        try:
            task_token = client.execute_task(
                config=pipeline_config,
                name="audio_transcription_task",
                threads=2
            )
            print(f"   âœ… Task started! Token: {task_token[:8]}...")
            
            # Monitor task progress
            print("   â³ Monitoring task progress...")
            for i in range(12):  # Check for 2 minutes (12 * 10 seconds)
                task_info = client.get_task_status(task_token)
                print(f"   ğŸ“Š Status: {task_info.status.value}, Progress: {task_info.progress}")
                
                if task_info.status.value == "completed":
                    print(f"   âœ… Task completed successfully!")
                    if task_info.result:
                        print(f"   ğŸ“ Result: {task_info.result}")
                    break
                elif task_info.status.value == "failed":
                    print(f"   âŒ Task failed: {task_info.error_message}")
                    break
                elif task_info.status.value == "cancelled":
                    print(f"   âš ï¸  Task was cancelled")
                    break
                
                time.sleep(10)  # Wait 10 seconds between checks
            else:
                print("   â° Task still running after 2 minutes. You can check status later.")
        
        except Exception as e:
            print(f"   âš ï¸  Task execution error: {e}")
        
        # Step 7: Webhook example (for when you have transcription results)
        print(f"\nğŸª Step 7: Webhook example...")
        try:
            webhook_data = {
                "event": "transcription_complete",
                "data": {
                    "filename": audio_file.name,
                    "status": "processing",
                    "message": "Audio transcription in progress"
                }
            }
            webhook_response = client.send_webhook(pipeline_token, webhook_data)
            print(f"   âœ… Webhook sent: {webhook_response}")
        except Exception as e:
            print(f"   âš ï¸  Webhook error: {e}")
        
        # Step 8: Clean up
        print(f"\nğŸ§¹ Step 8: Cleaning up...")
        cleanup_success = client.delete_pipeline(pipeline_token)
        print(f"   âœ… Pipeline deleted: {cleanup_success}")
        
        print(f"\nğŸ¯ PROCESSING COMPLETE!")
        print("ğŸ“‹ Summary:")
        print("   âœ… Pipeline validated and created")
        print("   âœ… MP4 file uploaded successfully")
        print("   âœ… Audio extraction and transcription initiated")
        print("   âœ… Multiple monitoring methods demonstrated")
        print("   âœ… Webhook integration shown")
        print("   âœ… Pipeline cleaned up")
        
    except DTCApiError as e:
        print(f"âŒ API Error: {e}")
        if e.status_code:
            print(f"   Status Code: {e.status_code}")
        if e.response_data:
            print(f"   Response Data: {e.response_data}")
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")


def show_pipeline_info():
    """Show information about the audio transcription pipeline."""
    print("\nğŸ“š AUDIO TRANSCRIPTION PIPELINE INFO")
    print("=" * 50)
    print("ğŸ¯ Pipeline Components:")
    print("   1. ğŸ—‚ï¸  Dropper - File upload source")
    print("   2. ğŸ” Parse - Extract audio/video from files")
    print("   3. ğŸµ Audio Transcribe - Convert speech to text")
    print("   4. ğŸ“¤ Response - Output transcribed text")
    print()
    print("âš™ï¸  Audio Transcription Settings:")
    print("   - Model: base (Whisper model)")
    print("   - Max seconds: 300 (5 minutes)")
    print("   - Min seconds: 240 (4 minutes)")
    print("   - Silence threshold: 0.25")
    print("   - VAD level: 1 (Voice Activity Detection)")
    print()
    print("ğŸ“ Supported File Types:")
    print("   - MP4 (video with audio)")
    print("   - MP3 (audio only)")
    print("   - WAV (audio only)")
    print("   - Other audio/video formats")
    print()
    print("ğŸ”„ Processing Flow:")
    print("   File â†’ Parse â†’ Audio Extract â†’ Transcribe â†’ Text Output")


def main():
    """Main function to process the user's audio file."""
    # Your specific file path
    audio_file_path = r"C:\Users\HendrikKrack\WorkBench\dtc-api\dtc-api-sdk\test_data\Q&A and check-in-20250623_125525-Meeting Recording.mp4"
    
    show_pipeline_info()
    process_audio_file(audio_file_path)


if __name__ == "__main__":
    main() 